{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780f1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 -q install utils==1.0.1\n",
    "# !pip3 -q install lightgbm==3.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042f9ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc,os,random\n",
    "import time,datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\n",
    "\n",
    "from utils import *\n",
    "# root = args.root\n",
    "# seed = args.seed\n",
    "# remark = args.remark\n",
    "# save_dir = args.save_dir\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d116440d",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716702ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "root=''\n",
    "remark=''\n",
    "save_dir=''\n",
    "seed=42\n",
    "id_name = 'customer_ID'\n",
    "label_name = 'target'\n",
    "\n",
    "eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6783db0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75a68711",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4237ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(f'train_data')\n",
    "test = pd.read_parquet(f'test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71855d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5531451, 191) (11363762, 190)\n"
     ]
    }
   ],
   "source": [
    "train_y =  pd.read_csv(f'{root}train_labels.csv')\n",
    "train = train.merge(train_y, how='left',on=id_name)\n",
    "\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba3f7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "878ac93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  target\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...       0\n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...       0\n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...       0\n",
       "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...       0\n",
       "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'{root}train_labels.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1370588d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>95.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2   P_2  D_39  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-03-09  93.0   0.0   \n",
       "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-04-07  93.0   0.0   \n",
       "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-05-28  95.0   9.0   \n",
       "\n",
       "   B_1    B_2  R_1   S_3  D_41  B_3  ...  D_137  D_138  D_139  D_140  D_141  \\\n",
       "0  0.0  100.0  0.0  12.0   0.0  0.0  ...    NaN    NaN    0.0    0.0    0.0   \n",
       "1  0.0  100.0  0.0  12.0   0.0  0.0  ...    NaN    NaN    0.0    0.0    0.0   \n",
       "2  2.0  100.0  0.0  12.0   0.0  0.0  ...    NaN    NaN    0.0    0.0    0.0   \n",
       "\n",
       "   D_142  D_143  D_144  D_145  target  \n",
       "0    NaN    0.0    0.0    0.0       0  \n",
       "1    NaN    0.0    0.0    0.0       0  \n",
       "2    NaN    0.0    0.0    0.0       0  \n",
       "\n",
       "[3 rows x 191 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cf8579",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc823691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "713d26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metric(labels,preds):\n",
    "    return amex_metric_mod(labels,preds)\n",
    "\n",
    "def amex_metric_mod(y_true, y_pred):\n",
    "        # y_true => \n",
    "        # 0          0\n",
    "        # 1          0\n",
    "        # 2          0\n",
    "        #           ..\n",
    "        # 5531449    0\n",
    "        # 5531450    0\n",
    "        # Name: target, Length: 2765213, dtype: int64\n",
    "        \n",
    "        # y_pred => [0.0018315  0.00164183 0.00174071 ... 0.00212767 0.00309472]\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))    \n",
    "\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "        # .argsort() => Return the integer indices that would sort the Series values.\n",
    "        # .argsort()[::-1] => reverse the sorted indices.\n",
    "        # labels => \n",
    "        # [[1.00000000e+00 9.97522107e-01]\n",
    "        # [1.00000000e+00 9.97491614e-01]\n",
    "        # ...\n",
    "        # [0.00000000e+00 8.86596095e-05]\n",
    "        # [0.00000000e+00 8.82186859e-05]]\n",
    "        # labels[:,0] denotes originl targets, labels[:,1] denotes predicted targets.\n",
    "        \n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "        # weights => [ 1  1  1 ... 20 20 20]\n",
    "        # np.cumsum(weights) => [       1        2        3 ... 42218046 42218066 42218086]\n",
    "        # np.sum(weights) => 42218086\n",
    "    \n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "        # cut_vals =>     \n",
    "        # [[1.         0.99752211]\n",
    "        #  [1.         0.99749161]\n",
    "        #  ...\n",
    "        #  [1.         0.69189778]\n",
    "        #  [0.         0.69189679]]    \n",
    "    \n",
    "        # np.sum(cut_vals[:,0]), np.sum(labels[:,0]) => 388343.0, 688746.0   \n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "        # top_four => 0.5638406611435856\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]] # i = 1,0\n",
    "            # when i==0 then labels => \n",
    "            # [[1.         0.67152673]\n",
    "            #  [1.         0.6808289 ]\n",
    "            #  ...\n",
    "            #  [0.         0.5255297 ]\n",
    "            #  [0.         0.0018315 ]]            \n",
    "        weights        = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weights / np.sum(weights))\n",
    "            # weight_random =>\n",
    "            # [2.36865309e-08 4.73730619e-08 7.10595928e-08 ... 9.99999052e-01\n",
    "            #  9.99999526e-01 1.00000000e+00]        \n",
    "        total_pos      = np.sum(labels[:, 0] *  weights)\n",
    "            # total_pos => 688746.0\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weights)\n",
    "            # cum_pos_found => \n",
    "            # [1.00000e+00 2.00000e+00 3.00000e+00 ... 6.88746e+05 6.88746e+05\n",
    "            #  6.88746e+05]        \n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "            # lorentz =>        \n",
    "            # [1.45191406e-06 2.90382812e-06 4.35574217e-06 ... 1.00000000e+00\n",
    "            #  1.00000000e+00 1.00000000e+00]        \n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weights)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "def Write_log(logFile,text,isPrint=False):\n",
    "    if isPrint:\n",
    "        print(text)\n",
    "    logFile.write(text)\n",
    "    logFile.write('\\n')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "187838bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lgb_train_and_predict(train, test, config, gkf=False, aug=None, output_root='./output/', run_id=None):\n",
    "    if not run_id:\n",
    "        run_id = 'run_lgb_' + datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        while os.path.exists(output_root+run_id+'/'):\n",
    "            time.sleep(1)\n",
    "            run_id = 'run_lgb_' + datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        output_path = output_root + f'{save_dir}/'\n",
    "    else:\n",
    "        output_path = output_root + run_id + '/'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "        \n",
    "#     os.system(f'cp ./*.py {output_path}')\n",
    "#     os.system(f'cp ./*.sh {output_path}')\n",
    "    \n",
    "    config['lgb_params']['seed'] = config['seed'] # config['seed'] = seed; defined in config.\n",
    "    oof, sub = None, None\n",
    "    if train is not None:\n",
    "        log = open(output_path + '/train.log','w',buffering=1)\n",
    "        log.write(str(config)+'\\n')\n",
    "        features = config['feature_name']\n",
    "        params = config['lgb_params']\n",
    "        rounds = config['rounds']\n",
    "        verbose = config['verbose_eval']\n",
    "        early_stopping_rounds = config['early_stopping_rounds']\n",
    "        folds = config['folds'] # 5\n",
    "        seed = config['seed']\n",
    "        \n",
    "        # assigning dataframe instead of series.\n",
    "        oof = train[[id_name]] # id-name = 'customer_ID'\n",
    "        oof[label_name] = 0 # creating column of zeros.\n",
    "\n",
    "        all_valid_metric,feature_importance = [],[]\n",
    "        if gkf: # group k fold. each customer_id appears once in one fold.\n",
    "            # dropping duplicate customer id from set of ['customer_ID',target].\n",
    "            tmp = train.loc[:,[id_name,label_name]].drop_duplicates(id_name).reset_index(drop=True)\n",
    "                # tmp.columns => Index(['customer_ID', 'target'], dtype='object').\n",
    "            skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "            split = skf.split(tmp,tmp[label_name])\n",
    "            new_split = []\n",
    "            for trn_index, val_index in split:\n",
    "                # for first split => trn_index, val_index =>\n",
    "                # [     1      2      3 ... 458905 458908 458911] [     0      4      5 ... 458909 458910 458912]\n",
    "                \n",
    "                # slice tmp, with row indexes present in 'trn_index', with column 'id_name'.\n",
    "                trn_uids = tmp.loc[trn_index,id_name].values\n",
    "                val_uids = tmp.loc[val_index,id_name].values\n",
    "                new_split.append((train.loc[train[id_name].isin(trn_uids)].index,train.loc[train[id_name].isin(val_uids)].index))\n",
    "            split = new_split\n",
    "            del new_split\n",
    "            _ = gc.collect()\n",
    "            \n",
    "            # skf = GroupKFold(n_splits=folds)\n",
    "            # split = skf.split(train,train[label_name],train[id_name])\n",
    "        else:\n",
    "            skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "            split = skf.split(train,train[label_name])\n",
    "            \n",
    "        for fold, (trn_index, val_index) in enumerate(split):\n",
    "            evals_result_dic = {}\n",
    "            \n",
    "            # training customer_ID's.\n",
    "            train_cids = train.loc[trn_index,id_name].values\n",
    "            \n",
    "            if aug: # if augmentation.\n",
    "                train_aug = aug.loc[aug[id_name].isin(train_cids)]\n",
    "                trn_data = lgb.Dataset(train.loc[trn_index,features].append(train_aug[features]), label=train.loc[trn_index,label_name].append(train_aug[label_name]))\n",
    "            else:\n",
    "                trn_data = lgb.Dataset(train.loc[trn_index,features], label=train.loc[trn_index,label_name])\n",
    "\n",
    "            val_data = lgb.Dataset(train.loc[val_index,features], label=train.loc[val_index,label_name])\n",
    "            model = lgb.train(params,\n",
    "#                 init_model = output_path + '/fold0.ckpt', # continue training from previous save.\n",
    "                init_model = output_path + '/fold%s.ckpt'%fold, \n",
    "                train_set  = trn_data,\n",
    "                num_boost_round   = rounds,\n",
    "                valid_sets = [trn_data,val_data],\n",
    "                evals_result = evals_result_dic,\n",
    "                early_stopping_rounds = early_stopping_rounds,\n",
    "                verbose_eval = verbose\n",
    "            )\n",
    "\n",
    "#             model = lgb.Booster(model_file=output_path + '/fold%s.ckpt'%fold) # loading model from saved ckpt.\n",
    "            model.save_model(output_path + '/fold%s.ckpt'%fold)\n",
    "\n",
    "            valid_preds = model.predict(train.loc[val_index,features], num_iteration=model.best_iteration)\n",
    "                # valid_preds => [0.0018315  0.00164183 0.00174071 ... 0.00257369 0.00212767 0.00309472]\n",
    "\n",
    "            # filling a slice of dataframe.\n",
    "            # replacing actual targets with predictions.\n",
    "            oof.loc[val_index,label_name] = valid_preds\n",
    "\n",
    "#             for i in range(len(evals_result_dic['valid_1'][params['metric']])//verbose):\n",
    "#                 Write_log(log,' - %i round - train_metric: %.6f - valid_metric: %.6f\\n'%(i*verbose,evals_result_dic['training'][params['metric']][i*verbose],evals_result_dic['valid_1'][params['metric']][i*verbose]))\n",
    "\n",
    "            all_valid_metric.append(Metric(train.loc[val_index,label_name],valid_preds))\n",
    "            Write_log(log,'- fold%s valid metric: %.6f\\n'%(fold,all_valid_metric[-1]))\n",
    "            \n",
    "            # Get feature importances. importance_type; How the importance is calculated. \n",
    "            # importance_type=“split” => result contains numbers of times the feature is used in a model.\n",
    "            # importance_type=“gain” => result contains total gains of splits which use the feature.\n",
    "            importance_gain = model.feature_importance(importance_type='gain')            \n",
    "            importance_split = model.feature_importance(importance_type='split')\n",
    "            \n",
    "            feature_name = model.feature_name()\n",
    "            feature_importance.append(pd.DataFrame({'feature_name':feature_name,'importance_gain':importance_gain,'importance_split':importance_split}))            \n",
    "        \n",
    "        # Concatenating pandas along axis=0.\n",
    "        feature_importance_df = pd.concat(feature_importance)\n",
    "        \n",
    "        feature_importance_df = feature_importance_df.groupby(['feature_name']).mean().reset_index()\n",
    "        feature_importance_df = feature_importance_df.sort_values(by=['importance_gain'],ascending=False)\n",
    "        feature_importance_df.to_csv(output_path + '/feature_importance.csv',index=False)\n",
    "\n",
    "        mean_valid_metric = np.mean(all_valid_metric)\n",
    "        global_valid_metric = Metric(train[label_name].values,oof[label_name].values)\n",
    "        Write_log(log,'all valid mean metric:%.6f, global valid metric:%.6f'%(mean_valid_metric,global_valid_metric))\n",
    "\n",
    "        oof.to_csv(output_path + '/oof.csv',index=False)\n",
    "\n",
    "        log.close()\n",
    "        os.rename(output_path + '/train.log', output_path + '/train_%.6f.log'%mean_valid_metric)\n",
    "\n",
    "        log_df = pd.DataFrame({'run_id':[run_id],'mean metric':[round(mean_valid_metric,6)],'global metric':[round(global_valid_metric,6)],'remark':[remark]})\n",
    "        if not os.path.exists(output_root + '/experiment_log.csv'):\n",
    "            log_df.to_csv(output_root + '/experiment_log.csv',index=False)\n",
    "        else:\n",
    "            log_df.to_csv(output_root + '/experiment_log.csv',index=False,header=None,mode='a')\n",
    "            # mode='a' => open for writing, appending to the end of file if it exists.\n",
    "\n",
    "    if test is not None:\n",
    "        sub = test[[id_name]] # assigning dataframe instead of series.\n",
    "        sub['prediction'] = 0\n",
    "        for fold in range(folds):\n",
    "            model = lgb.Booster(model_file=output_path + '/fold%s.ckpt'%fold)\n",
    "            test_preds = model.predict(test[features], num_iteration=model.best_iteration)\n",
    "            sub['prediction'] += (test_preds / folds)\n",
    "        sub[[id_name,'prediction']].to_csv(output_path + '/submission.csv.zip', compression='zip',index=False)\n",
    "#     if save_dir in output_path:\n",
    "#         os.rename(output_path,output_root+run_id+'/')\n",
    "        \n",
    "#     return oof,sub,(mean_valid_metric,global_valid_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b87f900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/ipykernel_launcher.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/ipykernel_launcher.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                               customer_ID    target\n",
       " 0        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.001716\n",
       " 1        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.001540\n",
       " 2        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.001630\n",
       " 3        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.001637\n",
       " 4        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.001119\n",
       " ...                                                    ...       ...\n",
       " 5531446  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  0.003640\n",
       " 5531447  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  0.002444\n",
       " 5531448  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  0.002510\n",
       " 5531449  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  0.002056\n",
       " 5531450  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  0.003002\n",
       " \n",
       " [5531451 rows x 2 columns],\n",
       "                                                 customer_ID  prediction\n",
       " 0         00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.193285\n",
       " 1         00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.174699\n",
       " 2         00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.174180\n",
       " 3         00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.197560\n",
       " 4         00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.141149\n",
       " ...                                                     ...         ...\n",
       " 11363757  fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...    0.135139\n",
       " 11363758  fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...    0.120410\n",
       " 11363759  fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...    0.108192\n",
       " 11363760  fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...    0.082603\n",
       " 11363761  fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...    0.100825\n",
       " \n",
       " [11363762 rows x 2 columns],\n",
       " (0.7310573207113716, 0.730956812196424))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_config = {\n",
    "    'lgb_params':{\n",
    "        'objective' : 'binary', # binary log loss classification (or logistic regression).\n",
    "        'metric' : 'binary_logloss',\n",
    "        'boosting': 'dart', # Dropouts meet Multiple Additive Regression Trees.\n",
    "        'max_depth' : -1, # limit the max depth for tree model. <= 0 means no limit.\n",
    "        'num_leaves' : 64, # max number of leaves in one tree.\n",
    "        'learning_rate' : 0.015, # 0.035\n",
    "        'bagging_freq': 5, # frequency for bagging, bagging at every kth (5th) iteration.\n",
    "                            #Every k-th (5-th) iteration, LightGBM will randomly select bagging_fraction * 100 % of the data to use for the next k iterations\n",
    "        \n",
    "        'bagging_fraction' : 0.7,\n",
    "        'feature_fraction' : 0.7, # LightGBM will select 70% of features before training each tree (iteration).\n",
    "        'min_data_in_leaf': 256, # minimal number of data in one leaf.\n",
    "        'max_bin': 63, # max number of bins that feature values will be bucketed in.\n",
    "        'min_data_in_bin': 256, # minimal number of data inside 'one bin'.\n",
    "        # 'min_sum_heassian_in_leaf': 10,\n",
    "        'tree_learner': 'serial', # single machine tree learner.\n",
    "        'boost_from_average': 'false', # adjusts initial score to the mean of labels for faster convergence.\n",
    "        'lambda_l1' : 0.1, # L1 regularization.\n",
    "        'lambda_l2' : 30, # L2 regularization\n",
    "        'num_threads': 11, # for the best speed, set this to the number of real CPU cores.\n",
    "        'verbosity' : 1,\n",
    "#         'device' : 'gpu'\n",
    "    },\n",
    "    'feature_name':[col for col in train.columns if col not in [id_name,label_name,'S_2']],\n",
    "    'rounds':50, # 4500\n",
    "    'early_stopping_rounds':100,\n",
    "    'verbose_eval':50,\n",
    "    'folds':5, # 5, (1; for deubg)\n",
    "    'seed':seed\n",
    "}\n",
    "\n",
    "Lgb_train_and_predict(train,test,lgb_config,gkf=True,aug=None, output_root='./o_debug/', run_id='LGB_with_series_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e606ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3283e750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>mean metric</th>\n",
       "      <th>global metric</th>\n",
       "      <th>remark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGB_with_series_feature</td>\n",
       "      <td>0.731081</td>\n",
       "      <td>0.730968</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGB_with_series_feature</td>\n",
       "      <td>0.731057</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGB_with_series_feature</td>\n",
       "      <td>0.731057</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    run_id  mean metric  global metric  remark\n",
       "0  LGB_with_series_feature     0.731081       0.730968     NaN\n",
       "1  LGB_with_series_feature     0.731057       0.730957     NaN\n",
       "2  LGB_with_series_feature     0.731057       0.730957     NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('o_debug/experiment_log.csv')\n",
    "# mean_metric = mean of folds.\n",
    "# global_metric = whole dataframe at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "571b8219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.001716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID    target\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.001716\n",
       "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.001540\n",
       "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.001630"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('o_debug/LGB_with_series_feature/oof.csv').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8bf2cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance_gain</th>\n",
       "      <th>importance_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_2</td>\n",
       "      <td>1.373261e+08</td>\n",
       "      <td>11535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_9</td>\n",
       "      <td>1.901178e+07</td>\n",
       "      <td>2985.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D_48</td>\n",
       "      <td>1.670780e+07</td>\n",
       "      <td>3578.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_name  importance_gain  importance_split\n",
       "0          P_2     1.373261e+08           11535.0\n",
       "1          B_9     1.901178e+07            2985.2\n",
       "2         D_48     1.670780e+07            3578.8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('o_debug/LGB_with_series_feature/feature_importance.csv').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e6c1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
