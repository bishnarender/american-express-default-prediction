{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modin.config as cfg\n",
    "# cfg.Engine.put(\"dask\")\n",
    "# cfg.CpuCount.put(12) # 12 cores\n",
    "# cfg.GpuCount.put(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from distributed import Client\n",
    "# client = Client(n_workers=cfg.CpuCount.get(), memory_limit=\"32GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-17T16:35:06.022906Z",
     "iopub.status.busy": "2023-02-17T16:35:06.022470Z",
     "iopub.status.idle": "2023-02-17T16:35:06.028854Z",
     "shell.execute_reply": "2023-02-17T16:35:06.027595Z",
     "shell.execute_reply.started": "2023-02-17T16:35:06.022871Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import numpy as np\n",
    "import numba\n",
    "numba.set_num_threads(12) # 12 = cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('use_numba', True)\n",
    "# import modin.pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T16:35:06.068388Z",
     "iopub.status.busy": "2023-02-17T16:35:06.067287Z",
     "iopub.status.idle": "2023-02-17T16:35:06.073857Z",
     "shell.execute_reply": "2023-02-17T16:35:06.072763Z",
     "shell.execute_reply.started": "2023-02-17T16:35:06.068320Z"
    }
   },
   "outputs": [],
   "source": [
    "import time,datetime\n",
    "from tqdm import tqdm\n",
    "# from multiprocessing import Pool as ThreadPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T16:35:06.076674Z",
     "iopub.status.busy": "2023-02-17T16:35:06.076076Z",
     "iopub.status.idle": "2023-02-17T16:35:06.086653Z",
     "shell.execute_reply": "2023-02-17T16:35:06.085849Z",
     "shell.execute_reply.started": "2023-02-17T16:35:06.076633Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = './' # ../input/amex-default-prediction\n",
    "data_dir_1 = './' # ../input/amex-default-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T01:34:04.176591Z",
     "iopub.status.busy": "2023-02-06T01:34:04.176153Z",
     "iopub.status.idle": "2023-02-06T01:46:14.267710Z",
     "shell.execute_reply": "2023-02-06T01:46:14.266262Z",
     "shell.execute_reply.started": "2023-02-06T01:34:04.176550Z"
    }
   },
   "outputs": [],
   "source": [
    "# # reading csv in chunks\n",
    "# train_data = pd.DataFrame()\n",
    "# with pd.read_csv(os.path.join(data_dir, 'train_data.csv'), chunksize=10**5) as reader:\n",
    "#     for counter, chunk in enumerate(reader):\n",
    "#         for column in chunk.columns:\n",
    "#             if str(chunk[column].dtype) == \"float64\":\n",
    "#                 chunk[column] = chunk[column].astype(np.float32)\n",
    "#             if str(chunk[column].dtype) == \"int64\":\n",
    "#                 chunk[column] = chunk[column].astype(np.int32)\n",
    "#         train_data = pd.concat([train_data, chunk])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T04:06:15.457777Z",
     "iopub.status.busy": "2023-02-07T04:06:15.457227Z",
     "iopub.status.idle": "2023-02-07T04:06:15.493413Z",
     "shell.execute_reply": "2023-02-07T04:06:15.492097Z",
     "shell.execute_reply.started": "2023-02-07T04:06:15.457729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5531451 entries, 0 to 5531450\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: float32(185), float64(1), int8(2), object(2)\n",
      "memory usage: 3.9+ GB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T01:46:55.508346Z",
     "iopub.status.busy": "2023-02-06T01:46:55.507824Z",
     "iopub.status.idle": "2023-02-06T01:46:55.729382Z",
     "shell.execute_reply": "2023-02-06T01:46:55.727964Z",
     "shell.execute_reply.started": "2023-02-06T01:46:55.508302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'R', nan, 'U', '-1'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['D_64'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T01:47:25.222725Z",
     "iopub.status.busy": "2023-02-06T01:47:25.222292Z",
     "iopub.status.idle": "2023-02-06T01:47:25.232060Z",
     "shell.execute_reply": "2023-02-06T01:47:25.231053Z",
     "shell.execute_reply.started": "2023-02-06T01:47:25.222693Z"
    }
   },
   "outputs": [],
   "source": [
    "def denoise(df):\n",
    "    df['D_63'] = df['D_63'].apply(lambda t: {'CR':0, 'XZ':1, 'XM':2, 'CO':3, 'CL':4, 'XL':5}[t]).astype(np.int8)\n",
    "    df['D_64'] = df['D_64'].apply(lambda t: {np.nan:-1, 'O':0, '-1':1, 'R':2, 'U':3}[t]).astype(np.int8)\n",
    "#     df['D_64'] = df['D_64'].apply(lambda t: {None:-1, 'O':0, '-1':1, 'R':2, 'U':3}[t]).astype(np.int8)    \n",
    "    for col in tqdm(df.columns):\n",
    "        if col not in ['customer_ID','S_2','D_63','D_64']:\n",
    "            df[col] = np.floor(df[col]*100)\n",
    "            # Return the floor of the input, element-wise. \n",
    "            # np.floor(np.array([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0])) => array([-2., -2., -1.,  0.,  1.,  1.,  2.])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T01:47:28.545942Z",
     "iopub.status.busy": "2023-02-06T01:47:28.545538Z",
     "iopub.status.idle": "2023-02-06T01:47:39.613942Z",
     "shell.execute_reply": "2023-02-06T01:47:39.612596Z",
     "shell.execute_reply.started": "2023-02-06T01:47:28.545910Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:04<00:00, 45.86it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = denoise(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T01:47:58.344658Z",
     "iopub.status.busy": "2023-02-06T01:47:58.343289Z",
     "iopub.status.idle": "2023-02-06T01:49:40.555541Z",
     "shell.execute_reply": "2023-02-06T01:49:40.554111Z",
     "shell.execute_reply.started": "2023-02-06T01:47:58.344614Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.to_parquet(\"train_data\",  compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T04:12:05.734849Z",
     "iopub.status.busy": "2023-02-07T04:12:05.734372Z",
     "iopub.status.idle": "2023-02-07T04:12:05.817325Z",
     "shell.execute_reply": "2023-02-07T04:12:05.814981Z",
     "shell.execute_reply.started": "2023-02-07T04:12:05.734798Z"
    }
   },
   "outputs": [],
   "source": [
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T01:57:47.682444Z",
     "iopub.status.busy": "2023-02-06T01:57:47.681506Z",
     "iopub.status.idle": "2023-02-06T02:24:46.458789Z",
     "shell.execute_reply": "2023-02-06T02:24:46.457176Z",
     "shell.execute_reply.started": "2023-02-06T01:57:47.682387Z"
    }
   },
   "outputs": [],
   "source": [
    "# reading csv in chunks\n",
    "# test_data = pd.DataFrame()\n",
    "# with pd.read_csv(os.path.join(data_dir, 'test_data.csv'), chunksize=10**5) as reader:\n",
    "#     for counter, chunk in enumerate(reader):\n",
    "#         for column in chunk.columns:\n",
    "#             if str(chunk[column].dtype) == \"float64\":\n",
    "#                 chunk[column] = chunk[column].astype(np.float32)\n",
    "#             if str(chunk[column].dtype) == \"int64\":\n",
    "#                 chunk[column] = chunk[column].astype(np.int32)\n",
    "#         test_data = pd.concat([test_data, chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T02:26:08.789890Z",
     "iopub.status.busy": "2023-02-06T02:26:08.789415Z",
     "iopub.status.idle": "2023-02-06T02:26:08.815976Z",
     "shell.execute_reply": "2023-02-06T02:26:08.814368Z",
     "shell.execute_reply.started": "2023-02-06T02:26:08.789851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11363762 entries, 0 to 11363761\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: float32(185), float64(1), int8(2), object(2)\n",
      "memory usage: 8.1+ GB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T02:25:40.720474Z",
     "iopub.status.busy": "2023-02-06T02:25:40.720018Z",
     "iopub.status.idle": "2023-02-06T02:26:03.406803Z",
     "shell.execute_reply": "2023-02-06T02:26:03.404583Z",
     "shell.execute_reply.started": "2023-02-06T02:25:40.720436Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:07<00:00, 24.01it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = denoise(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T02:26:17.801414Z",
     "iopub.status.busy": "2023-02-06T02:26:17.800930Z",
     "iopub.status.idle": "2023-02-06T02:29:49.795699Z",
     "shell.execute_reply": "2023-02-06T02:29:49.794146Z",
     "shell.execute_reply.started": "2023-02-06T02:26:17.801375Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.to_parquet(\"test_data\",  compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T01:55:00.484763Z",
     "iopub.status.busy": "2023-02-06T01:55:00.484259Z",
     "iopub.status.idle": "2023-02-06T01:55:00.696498Z",
     "shell.execute_reply": "2023-02-06T01:55:00.695152Z",
     "shell.execute_reply.started": "2023-02-06T01:55:00.484730Z"
    }
   },
   "outputs": [],
   "source": [
    "del test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_parquet(os.path.join(data_dir_1, 'train_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T06:36:36.446131Z",
     "iopub.status.busy": "2023-02-06T06:36:36.445685Z",
     "iopub.status.idle": "2023-02-06T06:36:57.586982Z",
     "shell.execute_reply": "2023-02-06T06:36:57.585885Z",
     "shell.execute_reply.started": "2023-02-06T06:36:36.446098Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_data = pd.read_parquet(os.path.join(data_dir_1, 'test_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_parquet(os.path.join(data_dir_1, 'train_data'))\n",
    "df_te = pd.read_parquet(os.path.join(data_dir_1, 'test_data'))\n",
    "df = pd.concat([df_tr,df_te], ignore_index=True)\n",
    "del df_tr, df_te\n",
    "_ = gc.collect()\n",
    "df = df.reset_index(drop=True)\n",
    "## df = df._to_pandas() # convert modin dataframe to pandas.\n",
    "# df.to_parquet(f'train_test_data', compression='gzip', index=False)\n",
    "# del df\n",
    "# _ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'int'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'modin.pandas.dataframe.DataFrame'>\n",
      "RangeIndex: 16895213 entries, 0 to 16895212\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: float32(185), object(2), int8(2), float64(1)\n",
      "memory usage: 12.1 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T05:28:19.870110Z",
     "iopub.status.busy": "2023-02-16T05:28:19.869295Z",
     "iopub.status.idle": "2023-02-16T05:28:20.066675Z",
     "shell.execute_reply": "2023-02-16T05:28:20.065291Z",
     "shell.execute_reply.started": "2023-02-16T05:28:19.870049Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T16:37:34.879630Z",
     "iopub.status.busy": "2023-02-17T16:37:34.878644Z",
     "iopub.status.idle": "2023-02-17T16:37:34.901714Z",
     "shell.execute_reply": "2023-02-17T16:37:34.900817Z",
     "shell.execute_reply.started": "2023-02-17T16:37:34.879590Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(df,cols,is_drop=True):\n",
    "    # cols => ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "    for col in cols:\n",
    "        # print('one hot encoding:',col)\n",
    "            # col, df[col].unique() => B_30, [  0. 200. 100.]\n",
    "        dummies = pd.get_dummies(pd.Series(df[col]),prefix='oneHot_%s'%col)        \n",
    "            # dummies.columns => Index(['oneHot_B_30_0.0', 'oneHot_B_30_100.0', 'oneHot_B_30_200.0'], dtype='object')\n",
    "            # dummies['oneHot_B_30_0.0'].unique() => [1 0]\n",
    "        df = pd.concat([df,dummies],axis=1)\n",
    "    if is_drop:\n",
    "        df.drop(cols, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def cat_feature(df):\n",
    "    # type(df) => <class 'pandas.core.frame.DataFrame'>\n",
    "    one_hot_features = [col for col in df.columns if 'oneHot' in col]  \n",
    "    if lastk is None:\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[one_hot_features].agg(['mean', 'std', 'sum', 'last'])\n",
    "        # sort=False; as customer_IDs are alphanumeric.\n",
    "        # num_agg_df => dataframe with columns (['mean', 'std', 'sum', 'last']) => \n",
    "        # MultiIndex([('oneHot_B_30_0.0', 'mean'),\n",
    "        #             ('oneHot_B_30_0.0', 'std'),\n",
    "        #             ('oneHot_B_30_0.0', 'sum'),\n",
    "        #             ('oneHot_B_30_0.0', 'last')],\n",
    "        #             ('oneHot_B_30_100.0', 'mean')],\n",
    "        #             ...\n",
    "        #             ...\n",
    "        #            )\n",
    "        #  and rows => unique customer ids\n",
    "\n",
    "    else:\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[one_hot_features].agg(['mean', 'std', 'sum'])     \n",
    "    # converting dataframe from 'MultiIndex' columns to 'Index' columns. \n",
    "    num_agg_df.columns = ['_'.join(x) for x in num_agg_df.columns]\n",
    "        # num_agg_df.columns =>\n",
    "        # Index(['oneHot_B_30_0.0_mean', 'oneHot_B_30_0.0_std', 'oneHot_B_30_0.0_sum',\n",
    "        #        'oneHot_B_30_0.0_last',        \n",
    "\n",
    "    if lastk is None:\n",
    "        # cat_features  => ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "        cat_agg_df = df.groupby(\"customer_ID\",sort=False)[cat_features].agg(['last', 'nunique']) \n",
    "        # nunique => Return counts of unique elements in category for a particular customer_ID.\n",
    "    else:\n",
    "        cat_agg_df = df.groupby(\"customer_ID\",sort=False)[cat_features].agg(['nunique'])\n",
    "    cat_agg_df.columns = ['_'.join(x) for x in cat_agg_df.columns]\n",
    "        # cat_agg_df.columns =>\n",
    "        # Index(['B_30_last', 'B_30_nunique', 'B_38_last', 'B_38_nunique', 'D_114_last',\n",
    "        #         ...\n",
    "        #         ...\n",
    "        #        'D_68_nunique'],\n",
    "        #       dtype='object')    \n",
    "        \n",
    "    return num_agg_df\n",
    "    count_agg_df = df.groupby(\"customer_ID\",sort=False)[['S_2']].agg(['count'])\n",
    "        # S_2 (timestamp_column)\n",
    "    count_agg_df.columns = ['_'.join(x) for x in count_agg_df.columns]\n",
    "        # count_agg_df.columns => Index(['S_2_count'], dtype='object')    \n",
    "    \n",
    "    df = pd.concat([num_agg_df, cat_agg_df, count_agg_df], axis=1).reset_index()\n",
    "    print('cat feature shape after engineering', df.shape )\n",
    "\n",
    "    return df\n",
    "\n",
    "def num_feature(df):\n",
    "    if num_features[0][:5] == 'rank_': \n",
    "        # num_features => ['rank_P_2', 'rank_D_39', 'rank_B_1', 'rank_B_2', 'rank_R_1', 'rank_S_3',......, 'rank_D_144', 'rank_D_145']        \n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[num_features].agg(['last'])\n",
    "        # .agg(['last']) => keep last rank of each group.\n",
    "\n",
    "    else:\n",
    "        # num_features => ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3',......, 'D_144', 'D_145']\n",
    "        # num_features[0], num_features[0][:5] => P_2, P_2         \n",
    "        if lastk is None:\n",
    "            num_agg_df = df.groupby(\"customer_ID\",sort=False)[num_features].agg(['mean', 'std', 'min', 'max', 'sum', 'last'])\n",
    "        else:\n",
    "            num_agg_df = df.groupby(\"customer_ID\",sort=False)[num_features].agg(['mean', 'std', 'min', 'max', 'sum'])\n",
    "    num_agg_df.columns = ['_'.join(x) for x in num_agg_df.columns]\n",
    "\n",
    "    if num_features[0][:5] != 'rank_':\n",
    "        for col in num_agg_df.columns:\n",
    "            num_agg_df[col] = num_agg_df[col] // 0.01 # e.g., mean 92.846153 convert 9284.0\n",
    "            # 92.846153 // 0.01 => 9284.0, 92.846153 / 0.01 => 9284.6153\n",
    "            \n",
    "    df = num_agg_df.reset_index()\n",
    "    print('num feature shape after engineering', df.shape )\n",
    "\n",
    "    return df\n",
    "\n",
    "def diff_feature(df):\n",
    "    diff_num_features = [f'diff_{col}' for col in num_features]\n",
    "    cids = df['customer_ID'].values\n",
    "    df = df.groupby('customer_ID')[num_features].diff().add_prefix('diff_')\n",
    "        # .diff() => difference of a DataFrame element compared with another element in the 'previous row' (default). \n",
    "        # before and after no change in row count.\n",
    "        # .add_prefix() => column labels are prefixed.        \n",
    "    df.insert(0,'customer_ID',cids)\n",
    "    if lastk is None:\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[diff_num_features].agg(['mean', 'std', 'min', 'max', 'sum', 'last'])\n",
    "    else:\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[diff_num_features].agg(['mean', 'std', 'min', 'max', 'sum'])\n",
    "    num_agg_df.columns = ['_'.join(x) for x in num_agg_df.columns]\n",
    "    for col in num_agg_df.columns:\n",
    "        num_agg_df[col] = num_agg_df[col] // 0.01\n",
    "\n",
    "    df = num_agg_df.reset_index()\n",
    "    print('diff feature shape after engineering', df.shape )\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T07:10:58.602849Z",
     "iopub.status.busy": "2023-02-06T07:10:58.602351Z",
     "iopub.status.idle": "2023-02-06T07:10:58.642764Z",
     "shell.execute_reply": "2023-02-06T07:10:58.640385Z",
     "shell.execute_reply.started": "2023-02-06T07:10:58.602810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5531451 entries, 0 to 5531450\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: float32(185), float64(1), int8(2), object(2)\n",
      "memory usage: 3.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T16:35:35.881291Z",
     "iopub.status.busy": "2023-02-17T16:35:35.880836Z",
     "iopub.status.idle": "2023-02-17T16:36:09.975465Z",
     "shell.execute_reply": "2023-02-17T16:36:09.974514Z",
     "shell.execute_reply.started": "2023-02-17T16:35:35.881256Z"
    }
   },
   "outputs": [],
   "source": [
    "n_cpu = 2 # 16\n",
    "transform = [['','rank_','ym_rank_'],[''],['']]\n",
    "# transform = [['rank_','ym_rank_'],[''],['']] # for debug\n",
    "\n",
    "\n",
    "for li, lastk in enumerate([None,3,6]):\n",
    "    for prefix in transform[li]:\n",
    "# #         df = pd.read_feather(f'./input/train.feather').append(pd.read_feather(f'./input/test.feather'), ignore_index=True).reset_index(drop=True)\n",
    "                # Append rows of other to the end of caller, returning a new object.\n",
    "        df = pd.read_parquet(os.path.join(data_dir_1, 'train_data')).append(pd.read_parquet(os.path.join(data_dir_1, 'test_data')), ignore_index=True).reset_index(drop=True) \n",
    "#         df = pd.read_parquet(os.path.join(data_dir_1, 'train_data')).reset_index(drop=True) # for debugging\n",
    "            \n",
    "\n",
    "        all_cols = [c for c in list(df.columns) if c not in ['customer_ID', 'S_2']]\n",
    "         # leaving 'customer_ID' and 'S_2'\n",
    "        \n",
    "        cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "        num_features = [col for col in all_cols if col not in cat_features]\n",
    "          # num_features => ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', ...,'S_17', ..., 'D_142', 'D_143', 'D_144', 'D_145']\n",
    "          #  D_136, D_137, D_138, D_142 etc. have NaN values.\n",
    "        \n",
    "        for col in [col for col in df.columns if 'S_' in col or 'P_' in col]:\n",
    "            if col != 'S_2':\n",
    "                df[col] = df[col].fillna(0)\n",
    "\n",
    "        if lastk is not None:\n",
    "            prefix = f'last{lastk}_' + prefix\n",
    "            print('all df shape',df.shape)\n",
    "            df['rank'] = df.groupby('customer_ID')['S_2'].rank(ascending=False)\n",
    "                # .rank(ascending=False) => rank such that current date will get 'poor rank' than old date.\n",
    "                \n",
    "            df = df.loc[df['rank']<=lastk].reset_index(drop=True) # keep top 3 rank or top 6 rank.\n",
    "            df = df.drop(['rank'],axis=1)\n",
    "            print(f'last {lastk} shape',df.shape)\n",
    "\n",
    "                    \n",
    "        if prefix == 'rank_':\n",
    "            cids = df['customer_ID'].values\n",
    "            # rank elements in each group. before and after no change in row count.\n",
    "            df = df.groupby('customer_ID')[num_features].rank(method='average', pct=True).add_prefix('rank_')\n",
    "                # .rank(pct=True) => Computes percentage rank of values i.e., arrange the ranks between '0.' and '1.'.\n",
    "                # e.g. => elements - 4, 4, 7, 7, 5, 6\n",
    "                # elements (sort) - 4, 4, 5, 6, 7, 7\n",
    "                # ranks    - 1, 2, 3, 4, 5, 6\n",
    "                # ranks (again) - 1.5, 1.5, 3, 4, 5.5, 5.5 => ranks of repeated items is averaged.\n",
    "                # ranks (pct) - 0.250000, 0.250000, 0.500000, 0.666667, 0.916667, 0.916667\n",
    "   \n",
    "            df.insert(0,'customer_ID',cids)\n",
    "                # .insert(0,'customer_ID',cids) => insert new column (with name 'customer_ID') at start (with values as 'cids').                \n",
    "            num_features = [f'rank_{col}' for col in num_features]\n",
    "\n",
    "        if prefix == 'ym_rank_': # ym => year-month\n",
    "            cids = df['customer_ID'].values\n",
    "            df['ym'] = df['S_2'].apply(lambda x:x[:7]) # pick year-month from date column 'S_2'.\n",
    "            df = df.groupby('ym')[num_features].rank(pct=True).add_prefix('ym_rank_')\n",
    "            num_features = [f'ym_rank_{col}' for col in num_features]\n",
    "            df.insert(0,'customer_ID',cids)\n",
    "\n",
    "        if prefix in ['','last3_']:\n",
    "            df = one_hot_encoding(df,cat_features,False)\n",
    "\n",
    "        # Series.cumsum() => Return cumulative sum over a DataFrame or Series axis.\n",
    "        vc = df['customer_ID'].value_counts(sort=False).cumsum()\n",
    "            # df['customer_ID'].value_counts(sort=False) => \n",
    "            # 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a    13\n",
    "            # 00000fd6641609c6ece5454664794f0340ad84dddce9a267a310b5ae68e9d8e5    13\n",
    "            # 00001b22f846c82c51f6e3958ccd81970162bae8b007e80662ef27519fcc18c1    13\n",
    "            \n",
    "            # df['customer_ID'].value_counts(sort=False).cumsum() => \n",
    "            # 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a         13\n",
    "            # 00000fd6641609c6ece5454664794f0340ad84dddce9a267a310b5ae68e9d8e5         26\n",
    "            # 00001b22f846c82c51f6e3958ccd81970162bae8b007e80662ef27519fcc18c1         39\n",
    "            # ...\n",
    "            \n",
    "        batch_size = int(np.ceil(len(vc) / n_cpu))        \n",
    "            # np.ceil(np.array([-1.7, -0.2, 0.2, 1.7, 2.0])) => array([-1., -0.,  1.,  2.,  2.]) \n",
    "            \n",
    "        dfs = []\n",
    "        start = 0\n",
    "        # make list of dataframe batches in accordance to cpu cores.\n",
    "        for i in range(min(n_cpu,int(np.ceil(len(vc) / batch_size)))):            \n",
    "            vc_ = vc[i*batch_size:(i+1)*batch_size]\n",
    "                # vc_ =>\n",
    "                # df['customer_ID'].value_counts(sort=False).cumsum() => \n",
    "                # 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a         13\n",
    "                # 00000fd6641609c6ece5454664794f0340ad84dddce9a267a310b5ae68e9d8e5         26\n",
    "                # ...\n",
    "                # fffff1d38b785cef84adeace64f8f83db3a0c31e8d92eaba8b115f71cab04681    5531451\n",
    "\n",
    "            dfs.append(df[start:vc_[-1]])\n",
    "                # df[start:vc_[-1]] => df[0:5531451]\n",
    "            start = vc_[-1]\n",
    "            \n",
    "#         pool = ThreadPool(n_cpu)\n",
    "\n",
    "        if prefix in ['','last3_']:\n",
    "#             cat_feature_df = pd.concat(pool.map(cat_feature,tqdm(dfs,desc='cat_feature'))).reset_index(drop=True)\n",
    "#             cat_feature_df.to_feather(f'./input/{prefix}cat_feature.feather')            \n",
    "            cat_feature_df = pd.concat([cat_feature(dfs[l]) for l in range(len(dfs))]).reset_index(drop=True) \n",
    "            cat_feature_df.to_parquet(f'{prefix}cat_feature', compression='gzip', index=False)\n",
    "                # tqdm(dfs,desc='cat_feature') => desc; add message to tqdm progress.\n",
    "                # pool.map(function_name, arguments)\n",
    "\n",
    "        if prefix in ['','last3_','last6_','rank_','ym_rank_']:\n",
    "#             num_feature_df = pd.concat(pool.map(num_feature,tqdm(dfs,desc='num_feature'))).reset_index(drop=True)\n",
    "#             num_feature_df.to_feather(f'./input/{prefix}num_feature.feather')\n",
    "            num_feature_df = pd.concat([num_feature(dfs[l]) for l in range(len(dfs))]).reset_index(drop=True) \n",
    "            num_feature_df.to_parquet(f'{prefix}num_feature', compression='gzip', index=False)\n",
    "\n",
    "        if prefix in ['','last3_']:\n",
    "#             diff_feature_df = pd.concat(pool.map(diff_feature,tqdm(dfs,desc='diff_feature'))).reset_index(drop=True)\n",
    "#             diff_feature_df.to_feather(f'./input/{prefix}diff_feature.feather')\n",
    "            diff_feature_df = pd.concat([diff_feature(dfs[l]) for l in range(len(dfs))]).reset_index(drop=True) \n",
    "            diff_feature_df.to_parquet(f'{prefix}diff_feature', compression='gzip', index=False) \n",
    "\n",
    "#         pool.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T06:54:06.132574Z",
     "iopub.status.busy": "2023-02-16T06:54:06.132076Z",
     "iopub.status.idle": "2023-02-16T06:54:09.364591Z",
     "shell.execute_reply": "2023-02-16T06:54:09.363165Z",
     "shell.execute_reply.started": "2023-02-16T06:54:06.132520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_ID          0\n",
       "S_2                  0\n",
       "P_2                  0\n",
       "D_39                 0\n",
       "B_1                  0\n",
       "                ...   \n",
       "D_141           101548\n",
       "D_142          4587043\n",
       "D_143           101548\n",
       "D_144            40727\n",
       "D_145           101548\n",
       "Length: 190, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count nan values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T06:58:23.706528Z",
     "iopub.status.busy": "2023-02-16T06:58:23.705821Z",
     "iopub.status.idle": "2023-02-16T06:58:24.098304Z",
     "shell.execute_reply": "2023-02-16T06:58:24.097324Z",
     "shell.execute_reply.started": "2023-02-16T06:58:23.706465Z"
    }
   },
   "outputs": [],
   "source": [
    "# df[df['customer_ID'] == '0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a'][['S_2', 'B_30']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T07:03:50.741228Z",
     "iopub.status.busy": "2023-02-16T07:03:50.740674Z",
     "iopub.status.idle": "2023-02-16T07:03:51.120673Z",
     "shell.execute_reply": "2023-02-16T07:03:51.119372Z",
     "shell.execute_reply.started": "2023-02-16T07:03:50.741186Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
