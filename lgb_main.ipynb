{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e09ecff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc,os,random\n",
    "import time,datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\n",
    "\n",
    "from utils import *\n",
    "# root = args.root\n",
    "# seed = args.seed\n",
    "# remark = args.remark\n",
    "# save_dir = args.save_dir\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d6e907",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a02fec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='.'\n",
    "remark=''\n",
    "save_dir=''\n",
    "seed=42\n",
    "id_name = 'customer_ID'\n",
    "label_name = 'target'\n",
    "\n",
    "eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a7624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4b91fda",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90074849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb did not like normalize data so somewhat denormalizing it.\n",
    "zz = pd.read_parquet(f'{root}/extra/tmp_feature')\n",
    "for col in zz.columns:\n",
    "    if 'target' in col:\n",
    "        zz[col] = zz[col] // 0.001        \n",
    "zz.to_parquet(f'{root}/extra/tmp_feature', compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8c16abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and saving manual features (polars library).\n",
    "df = pl.read_parquet(f'{root}/extra/cat_feature')\n",
    "for fn in ['num','diff','rank_num','last3_cat','last3_num','last3_diff', 'last6_num','ym_rank_num','tmp']:\n",
    "    df = df.join(pl.read_parquet(f'{root}/extra/{fn}_feature'), on=\"customer_ID\", how=\"left\", ) \n",
    "\n",
    "train_y =  pl.read_csv(f'{root}/train_labels.csv')\n",
    "df.filter(~pl.col(\"customer_ID\").is_in(train_y[\"customer_ID\"]),\n",
    "         ).write_parquet(f'{root}/extra/lgb_main_test_feature', compression='gzip')\n",
    "df = df.filter(pl.col(\"customer_ID\").is_in(train_y[\"customer_ID\"]),)\n",
    "df = df.join(train_y, on=\"customer_ID\", how=\"left\", ) \n",
    "df.write_parquet(f'{root}/extra/lgb_main_train_feature', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a0114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9711efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66a204bc",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55e719ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y =  pl.read_csv(f'{root}train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573f6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6781f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metric(labels,preds):\n",
    "    return amex_metric_mod(labels,preds)\n",
    "\n",
    "def amex_metric_mod(y_true, y_pred):\n",
    "        # y_true => \n",
    "        # 0          0\n",
    "        # 1          0\n",
    "        # 2          0\n",
    "        #           ..\n",
    "        # 5531449    0\n",
    "        # 5531450    0\n",
    "        # Name: target, Length: 2765213, dtype: int64\n",
    "        \n",
    "        # y_pred => [0.0018315  0.00164183 0.00174071 ... 0.00212767 0.00309472]\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))    \n",
    "\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "        # .argsort() => Return the integer indices that would sort the Series values.\n",
    "        # .argsort()[::-1] => reverse the sorted indices.\n",
    "        # labels => \n",
    "        # [[1.00000000e+00 9.97522107e-01]\n",
    "        # [1.00000000e+00 9.97491614e-01]\n",
    "        # ...\n",
    "        # [0.00000000e+00 8.86596095e-05]\n",
    "        # [0.00000000e+00 8.82186859e-05]]\n",
    "        # labels[:,0] denotes originl targets, labels[:,1] denotes predicted targets.\n",
    "        \n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "        # weights => [ 1  1  1 ... 20 20 20]\n",
    "        # np.cumsum(weights) => [       1        2        3 ... 42218046 42218066 42218086]\n",
    "        # np.sum(weights) => 42218086\n",
    "    \n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "        # cut_vals =>     \n",
    "        # [[1.         0.99752211]\n",
    "        #  [1.         0.99749161]\n",
    "        #  ...\n",
    "        #  [1.         0.69189778]\n",
    "        #  [0.         0.69189679]]    \n",
    "    \n",
    "        # np.sum(cut_vals[:,0]), np.sum(labels[:,0]) => 388343.0, 688746.0   \n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "        # top_four => 0.5638406611435856\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]] # i = 1,0\n",
    "            # when i==0 then labels => \n",
    "            # [[1.         0.67152673]\n",
    "            #  [1.         0.6808289 ]\n",
    "            #  ...\n",
    "            #  [0.         0.5255297 ]\n",
    "            #  [0.         0.0018315 ]]            \n",
    "        weights        = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weights / np.sum(weights))\n",
    "            # weight_random =>\n",
    "            # [2.36865309e-08 4.73730619e-08 7.10595928e-08 ... 9.99999052e-01\n",
    "            #  9.99999526e-01 1.00000000e+00]        \n",
    "        total_pos      = np.sum(labels[:, 0] *  weights)\n",
    "            # total_pos => 688746.0\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weights)\n",
    "            # cum_pos_found => \n",
    "            # [1.00000e+00 2.00000e+00 3.00000e+00 ... 6.88746e+05 6.88746e+05\n",
    "            #  6.88746e+05]        \n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "            # lorentz =>        \n",
    "            # [1.45191406e-06 2.90382812e-06 4.35574217e-06 ... 1.00000000e+00\n",
    "            #  1.00000000e+00 1.00000000e+00]        \n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weights)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "def Write_log(logFile,text,isPrint=False):\n",
    "    if isPrint:\n",
    "        print(text)\n",
    "    logFile.write(text)\n",
    "    logFile.write('\\n')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd152742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lgb_train_and_predict(train, test, config, gkf=False, aug=None, output_root='./output/', run_id=None):\n",
    "    if not run_id:\n",
    "        run_id = 'run_lgb_' + datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        while os.path.exists(output_root+run_id+'/'):\n",
    "            time.sleep(1)\n",
    "            run_id = 'run_lgb_' + datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        output_path = output_root + f'{save_dir}/'\n",
    "    else:\n",
    "        output_path = output_root + run_id + '/'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "        \n",
    "#     os.system(f'cp ./*.py {output_path}')\n",
    "#     os.system(f'cp ./*.sh {output_path}')\n",
    "    \n",
    "    config['lgb_params']['seed'] = config['seed'] # config['seed'] = seed; defined in config.\n",
    "    oof, sub = None, None\n",
    "    if train is not None:\n",
    "        log = open(output_path + '/train.log','w',buffering=1)\n",
    "        log.write(str(config)+'\\n')\n",
    "        features = config['feature_name']\n",
    "        params = config['lgb_params']\n",
    "        rounds = config['rounds']\n",
    "        verbose = config['verbose_eval']\n",
    "        early_stopping_rounds = config['early_stopping_rounds']\n",
    "        folds = config['folds'] # 5\n",
    "        seed = config['seed']\n",
    "        \n",
    "        # assigning dataframe instead of series.\n",
    "        oof = train[[id_name]] # id-name = 'customer_ID'\n",
    "        oof[label_name] = 0 # creating column of zeros.\n",
    "\n",
    "        all_valid_metric,feature_importance = [],[]\n",
    "        if gkf: # group k fold. each customer_id appears once in one fold.\n",
    "            # dropping duplicate customer id from set of ['customer_ID',target].\n",
    "            tmp = train.loc[:,[id_name,label_name]].drop_duplicates(id_name).reset_index(drop=True)\n",
    "                # tmp.columns => Index(['customer_ID', 'target'], dtype='object').\n",
    "            skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "            split = skf.split(tmp,tmp[label_name])\n",
    "            new_split = []\n",
    "            for trn_index, val_index in split:\n",
    "                # for first split => trn_index, val_index =>\n",
    "                # [     1      2      3 ... 458905 458908 458911] [     0      4      5 ... 458909 458910 458912]\n",
    "                \n",
    "                # slice tmp, with row indexes present in 'trn_index', with column 'id_name'.\n",
    "                trn_uids = tmp.loc[trn_index,id_name].values\n",
    "                val_uids = tmp.loc[val_index,id_name].values\n",
    "                new_split.append((train.loc[train[id_name].isin(trn_uids)].index,train.loc[train[id_name].isin(val_uids)].index))\n",
    "            split = new_split\n",
    "            del new_split\n",
    "            _ = gc.collect()\n",
    "            \n",
    "            # skf = GroupKFold(n_splits=folds)\n",
    "            # split = skf.split(train,train[label_name],train[id_name])\n",
    "        else:\n",
    "            skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "            split = skf.split(train,train[label_name])\n",
    "            \n",
    "        for fold, (trn_index, val_index) in enumerate(split):\n",
    "            evals_result_dic = {}\n",
    "            \n",
    "            # training customer_ID's.\n",
    "            train_cids = train.loc[trn_index,id_name].values\n",
    "            \n",
    "            if aug: # if augmentation.\n",
    "                train_aug = aug.loc[aug[id_name].isin(train_cids)]\n",
    "                trn_data = lgb.Dataset(train.loc[trn_index,features].append(train_aug[features]), label=train.loc[trn_index,label_name].append(train_aug[label_name]))\n",
    "            else:\n",
    "                trn_data = lgb.Dataset(train.loc[trn_index,features], label=train.loc[trn_index,label_name])\n",
    "\n",
    "            val_data = lgb.Dataset(train.loc[val_index,features], label=train.loc[val_index,label_name])\n",
    "            model = lgb.train(params,\n",
    "                init_model = output_path + 'foldX.ckpt', # continue training from previous save.\n",
    "#                 init_model = output_path + 'fold%s.ckpt'%fold, \n",
    "                train_set  = trn_data,\n",
    "                num_boost_round   = rounds,\n",
    "                valid_sets = [trn_data,val_data],\n",
    "                evals_result = evals_result_dic,\n",
    "                early_stopping_rounds = early_stopping_rounds,\n",
    "                verbose_eval = verbose\n",
    "            )\n",
    "\n",
    "#             model = lgb.Booster(model_file=output_path + '/fold%s.ckpt'%fold) # loading model from saved ckpt.\n",
    "            model.save_model(output_path + '/fold%s.ckpt'%fold)\n",
    "\n",
    "            valid_preds = model.predict(train.loc[val_index,features], num_iteration=model.best_iteration)\n",
    "                # valid_preds => [0.0018315  0.00164183 0.00174071 ... 0.00257369 0.00212767 0.00309472]\n",
    "\n",
    "            # filling a slice of dataframe.\n",
    "            # replacing actual targets with predictions.\n",
    "            oof.loc[val_index,label_name] = valid_preds\n",
    "\n",
    "#             for i in range(len(evals_result_dic['valid_1'][params['metric']])//verbose):\n",
    "#                 Write_log(log,' - %i round - train_metric: %.6f - valid_metric: %.6f\\n'%(i*verbose,evals_result_dic['training'][params['metric']][i*verbose],evals_result_dic['valid_1'][params['metric']][i*verbose]))\n",
    "\n",
    "            all_valid_metric.append(Metric(train.loc[val_index,label_name],valid_preds))\n",
    "            Write_log(log,'- fold%s valid metric: %.6f\\n'%(fold,all_valid_metric[-1]))\n",
    "            \n",
    "            # Get feature importances. importance_type; How the importance is calculated. \n",
    "            # importance_type=“split” => result contains numbers of times the feature is used in a model.\n",
    "            # importance_type=“gain” => result contains total gains of splits which use the feature.\n",
    "            importance_gain = model.feature_importance(importance_type='gain')            \n",
    "            importance_split = model.feature_importance(importance_type='split')\n",
    "            \n",
    "            feature_name = model.feature_name()\n",
    "            feature_importance.append(pd.DataFrame({'feature_name':feature_name,'importance_gain':importance_gain,'importance_split':importance_split}))            \n",
    "        \n",
    "        # Concatenating pandas along axis=0.\n",
    "        feature_importance_df = pd.concat(feature_importance)\n",
    "        \n",
    "        feature_importance_df = feature_importance_df.groupby(['feature_name']).mean().reset_index()\n",
    "        feature_importance_df = feature_importance_df.sort_values(by=['importance_gain'],ascending=False)\n",
    "        feature_importance_df.to_csv(output_path + '/feature_importance.csv',index=False)\n",
    "\n",
    "        mean_valid_metric = np.mean(all_valid_metric)\n",
    "        global_valid_metric = Metric(train[label_name].values,oof[label_name].values)\n",
    "        Write_log(log,'all valid mean metric:%.6f, global valid metric:%.6f'%(mean_valid_metric,global_valid_metric))\n",
    "\n",
    "        oof.to_csv(output_path + '/oof.csv',index=False)\n",
    "\n",
    "        log.close()\n",
    "        os.rename(output_path + '/train.log', output_path + '/train_%.6f.log'%mean_valid_metric)\n",
    "\n",
    "        log_df = pd.DataFrame({'run_id':[run_id],'mean metric':[round(mean_valid_metric,6)],'global metric':[round(global_valid_metric,6)],'remark':[remark]})\n",
    "        if not os.path.exists(output_root + '/experiment_log.csv'):\n",
    "            log_df.to_csv(output_root + '/experiment_log.csv',index=False)\n",
    "        else:\n",
    "            log_df.to_csv(output_root + '/experiment_log.csv',index=False,header=None,mode='a')\n",
    "            \n",
    "    features = config['feature_name']\n",
    "    folds = config['folds']            \n",
    "    if test is not None:\n",
    "        sub = test[[id_name]] # assigning dataframe instead of series.\n",
    "        sub['prediction'] = 0\n",
    "        for fold in range(folds):\n",
    "            model = lgb.Booster(model_file=output_path + '/fold%s.ckpt'%fold)\n",
    "            test_preds = model.predict(test[features], num_iteration=model.best_iteration)\n",
    "            sub['prediction'] += (test_preds / folds)\n",
    "        sub[[id_name,'prediction']].to_csv(output_path + '/submission_1.csv.zip', compression='zip',index=False)\n",
    "        \n",
    "#     if save_dir in output_path:\n",
    "#         os.rename(output_path,output_root+run_id+'/')\n",
    "        \n",
    "#     return oof,sub,(mean_valid_metric,global_valid_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2935581b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb710ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_config = {\n",
    "    'lgb_params':{\n",
    "                  'objective' : 'binary',\n",
    "                  'metric' : 'binary_logloss',\n",
    "                  'boosting': 'dart',\n",
    "                  'max_depth' : -1,\n",
    "                  'num_leaves' : 64,\n",
    "                  'learning_rate' : 0.0100, # 0.035 \n",
    "                  'bagging_freq': 5,\n",
    "                  'bagging_fraction' : 0.75,\n",
    "                  'feature_fraction' : 0.05,\n",
    "                  'min_data_in_leaf': 256,\n",
    "                  'max_bin': 63,\n",
    "                  'min_data_in_bin': 256,\n",
    "                  # 'min_sum_heassian_in_leaf': 10,\n",
    "                  'tree_learner': 'serial',\n",
    "                  'boost_from_average': 'false',\n",
    "                  'lambda_l1' : 0.1,\n",
    "                  'lambda_l2' : 30,\n",
    "                  'num_threads': 11, # cpu cores\n",
    "                  'verbosity' : 0, # 1\n",
    "    },\n",
    "    'feature_name':[],\n",
    "    'rounds':500,\n",
    "    'early_stopping_rounds':100,\n",
    "    'verbose_eval':50,\n",
    "    'folds':5,\n",
    "    'seed':seed\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c67d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "999485ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(f'{root}/extra/lgb_main_train_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42d97d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.283519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[10050]\ttraining's binary_logloss: 0.174014\tvalid_1's binary_logloss: 0.200838\n",
      "[10100]\ttraining's binary_logloss: 0.17385\tvalid_1's binary_logloss: 0.200843\n",
      "[10150]\ttraining's binary_logloss: 0.173746\tvalid_1's binary_logloss: 0.200839\n",
      "[10200]\ttraining's binary_logloss: 0.173673\tvalid_1's binary_logloss: 0.200845\n",
      "[10250]\ttraining's binary_logloss: 0.173499\tvalid_1's binary_logloss: 0.200856\n",
      "[10300]\ttraining's binary_logloss: 0.173352\tvalid_1's binary_logloss: 0.200864\n",
      "[10350]\ttraining's binary_logloss: 0.173212\tvalid_1's binary_logloss: 0.200868\n",
      "[10400]\ttraining's binary_logloss: 0.173134\tvalid_1's binary_logloss: 0.200869\n",
      "[10450]\ttraining's binary_logloss: 0.173082\tvalid_1's binary_logloss: 0.200865\n",
      "[10500]\ttraining's binary_logloss: 0.172827\tvalid_1's binary_logloss: 0.20088\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.034444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[10050]\ttraining's binary_logloss: 0.180489\tvalid_1's binary_logloss: 0.17487\n",
      "[10100]\ttraining's binary_logloss: 0.180305\tvalid_1's binary_logloss: 0.174891\n",
      "[10150]\ttraining's binary_logloss: 0.180187\tvalid_1's binary_logloss: 0.174891\n",
      "[10200]\ttraining's binary_logloss: 0.18011\tvalid_1's binary_logloss: 0.174888\n",
      "[10250]\ttraining's binary_logloss: 0.17992\tvalid_1's binary_logloss: 0.174901\n",
      "[10300]\ttraining's binary_logloss: 0.179759\tvalid_1's binary_logloss: 0.174915\n",
      "[10350]\ttraining's binary_logloss: 0.179609\tvalid_1's binary_logloss: 0.174932\n",
      "[10400]\ttraining's binary_logloss: 0.179526\tvalid_1's binary_logloss: 0.174925\n",
      "[10450]\ttraining's binary_logloss: 0.179468\tvalid_1's binary_logloss: 0.174929\n",
      "[10500]\ttraining's binary_logloss: 0.179195\tvalid_1's binary_logloss: 0.174941\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.246078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[10050]\ttraining's binary_logloss: 0.181404\tvalid_1's binary_logloss: 0.171185\n",
      "[10100]\ttraining's binary_logloss: 0.181229\tvalid_1's binary_logloss: 0.171194\n",
      "[10150]\ttraining's binary_logloss: 0.181115\tvalid_1's binary_logloss: 0.171208\n",
      "[10200]\ttraining's binary_logloss: 0.181034\tvalid_1's binary_logloss: 0.171207\n",
      "[10250]\ttraining's binary_logloss: 0.180843\tvalid_1's binary_logloss: 0.171215\n",
      "[10300]\ttraining's binary_logloss: 0.180686\tvalid_1's binary_logloss: 0.171233\n",
      "[10350]\ttraining's binary_logloss: 0.180539\tvalid_1's binary_logloss: 0.171237\n",
      "[10400]\ttraining's binary_logloss: 0.180446\tvalid_1's binary_logloss: 0.171252\n",
      "[10450]\ttraining's binary_logloss: 0.180383\tvalid_1's binary_logloss: 0.171247\n",
      "[10500]\ttraining's binary_logloss: 0.180114\tvalid_1's binary_logloss: 0.171263\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 12.093420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[10050]\ttraining's binary_logloss: 0.179816\tvalid_1's binary_logloss: 0.177562\n",
      "[10100]\ttraining's binary_logloss: 0.179646\tvalid_1's binary_logloss: 0.177572\n",
      "[10150]\ttraining's binary_logloss: 0.179534\tvalid_1's binary_logloss: 0.177582\n",
      "[10200]\ttraining's binary_logloss: 0.179457\tvalid_1's binary_logloss: 0.177579\n",
      "[10250]\ttraining's binary_logloss: 0.179271\tvalid_1's binary_logloss: 0.177593\n",
      "[10300]\ttraining's binary_logloss: 0.179115\tvalid_1's binary_logloss: 0.1776\n",
      "[10350]\ttraining's binary_logloss: 0.178967\tvalid_1's binary_logloss: 0.177607\n",
      "[10400]\ttraining's binary_logloss: 0.17889\tvalid_1's binary_logloss: 0.177605\n",
      "[10450]\ttraining's binary_logloss: 0.17883\tvalid_1's binary_logloss: 0.177605\n",
      "[10500]\ttraining's binary_logloss: 0.178568\tvalid_1's binary_logloss: 0.177619\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 12.327818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[10050]\ttraining's binary_logloss: 0.180774\tvalid_1's binary_logloss: 0.17376\n",
      "[10100]\ttraining's binary_logloss: 0.180595\tvalid_1's binary_logloss: 0.173769\n",
      "[10150]\ttraining's binary_logloss: 0.180481\tvalid_1's binary_logloss: 0.173773\n",
      "[10200]\ttraining's binary_logloss: 0.180413\tvalid_1's binary_logloss: 0.173774\n",
      "[10250]\ttraining's binary_logloss: 0.180227\tvalid_1's binary_logloss: 0.173777\n",
      "[10300]\ttraining's binary_logloss: 0.180075\tvalid_1's binary_logloss: 0.173782\n",
      "[10350]\ttraining's binary_logloss: 0.179932\tvalid_1's binary_logloss: 0.173784\n",
      "[10400]\ttraining's binary_logloss: 0.179845\tvalid_1's binary_logloss: 0.17379\n",
      "[10450]\ttraining's binary_logloss: 0.179788\tvalid_1's binary_logloss: 0.173785\n",
      "[10500]\ttraining's binary_logloss: 0.179525\tvalid_1's binary_logloss: 0.173797\n"
     ]
    }
   ],
   "source": [
    "lgb_config['feature_name'] = [col for col in train.columns if col not in [id_name,label_name,'S_2'] and 'target' not in col]\n",
    "test = None\n",
    "Lgb_train_and_predict(train,test,lgb_config,aug=None,output_root='./o_debug/',run_id='LGB_with_manual_feature')\n",
    "# 0.1736 fold4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "503cadab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.686350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[5550]\ttraining's binary_logloss: 0.180955\tvalid_1's binary_logloss: 0.204425\n",
      "[5600]\ttraining's binary_logloss: 0.180759\tvalid_1's binary_logloss: 0.2044\n",
      "[5650]\ttraining's binary_logloss: 0.180625\tvalid_1's binary_logloss: 0.204378\n",
      "[5700]\ttraining's binary_logloss: 0.18054\tvalid_1's binary_logloss: 0.204381\n",
      "[5750]\ttraining's binary_logloss: 0.180306\tvalid_1's binary_logloss: 0.204343\n",
      "[5800]\ttraining's binary_logloss: 0.18012\tvalid_1's binary_logloss: 0.20432\n",
      "[5850]\ttraining's binary_logloss: 0.179942\tvalid_1's binary_logloss: 0.204289\n",
      "[5900]\ttraining's binary_logloss: 0.179847\tvalid_1's binary_logloss: 0.204288\n",
      "[5950]\ttraining's binary_logloss: 0.179779\tvalid_1's binary_logloss: 0.204272\n",
      "[6000]\ttraining's binary_logloss: 0.179466\tvalid_1's binary_logloss: 0.204232\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.444004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[5550]\ttraining's binary_logloss: 0.185984\tvalid_1's binary_logloss: 0.184202\n",
      "[5600]\ttraining's binary_logloss: 0.185771\tvalid_1's binary_logloss: 0.18419\n",
      "[5650]\ttraining's binary_logloss: 0.185633\tvalid_1's binary_logloss: 0.184181\n",
      "[5700]\ttraining's binary_logloss: 0.185541\tvalid_1's binary_logloss: 0.184172\n",
      "[5750]\ttraining's binary_logloss: 0.185295\tvalid_1's binary_logloss: 0.184133\n",
      "[5800]\ttraining's binary_logloss: 0.1851\tvalid_1's binary_logloss: 0.184116\n",
      "[5850]\ttraining's binary_logloss: 0.184903\tvalid_1's binary_logloss: 0.184086\n",
      "[5900]\ttraining's binary_logloss: 0.184798\tvalid_1's binary_logloss: 0.18409\n",
      "[5950]\ttraining's binary_logloss: 0.184726\tvalid_1's binary_logloss: 0.184084\n",
      "[6000]\ttraining's binary_logloss: 0.184403\tvalid_1's binary_logloss: 0.184051\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.728399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[5550]\ttraining's binary_logloss: 0.186524\tvalid_1's binary_logloss: 0.18206\n",
      "[5600]\ttraining's binary_logloss: 0.186318\tvalid_1's binary_logloss: 0.182046\n",
      "[5650]\ttraining's binary_logloss: 0.186183\tvalid_1's binary_logloss: 0.182033\n",
      "[5700]\ttraining's binary_logloss: 0.186092\tvalid_1's binary_logloss: 0.182028\n",
      "[5750]\ttraining's binary_logloss: 0.185842\tvalid_1's binary_logloss: 0.182005\n",
      "[5800]\ttraining's binary_logloss: 0.185652\tvalid_1's binary_logloss: 0.181985\n",
      "[5850]\ttraining's binary_logloss: 0.185459\tvalid_1's binary_logloss: 0.181957\n",
      "[5900]\ttraining's binary_logloss: 0.185358\tvalid_1's binary_logloss: 0.18195\n",
      "[5950]\ttraining's binary_logloss: 0.185288\tvalid_1's binary_logloss: 0.181943\n",
      "[6000]\ttraining's binary_logloss: 0.184963\tvalid_1's binary_logloss: 0.181924\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.563716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[5550]\ttraining's binary_logloss: 0.187225\tvalid_1's binary_logloss: 0.179405\n",
      "[5600]\ttraining's binary_logloss: 0.187007\tvalid_1's binary_logloss: 0.17939\n",
      "[5650]\ttraining's binary_logloss: 0.18686\tvalid_1's binary_logloss: 0.179375\n",
      "[5700]\ttraining's binary_logloss: 0.186766\tvalid_1's binary_logloss: 0.179365\n",
      "[5750]\ttraining's binary_logloss: 0.186542\tvalid_1's binary_logloss: 0.179348\n",
      "[5800]\ttraining's binary_logloss: 0.186346\tvalid_1's binary_logloss: 0.179334\n",
      "[5850]\ttraining's binary_logloss: 0.186161\tvalid_1's binary_logloss: 0.179324\n",
      "[5900]\ttraining's binary_logloss: 0.186052\tvalid_1's binary_logloss: 0.179313\n",
      "[5950]\ttraining's binary_logloss: 0.185977\tvalid_1's binary_logloss: 0.179301\n",
      "[6000]\ttraining's binary_logloss: 0.18565\tvalid_1's binary_logloss: 0.179275\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.541447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[5550]\ttraining's binary_logloss: 0.187158\tvalid_1's binary_logloss: 0.179595\n",
      "[5600]\ttraining's binary_logloss: 0.186941\tvalid_1's binary_logloss: 0.17958\n",
      "[5650]\ttraining's binary_logloss: 0.186794\tvalid_1's binary_logloss: 0.179564\n",
      "[5700]\ttraining's binary_logloss: 0.186693\tvalid_1's binary_logloss: 0.179552\n",
      "[5750]\ttraining's binary_logloss: 0.186459\tvalid_1's binary_logloss: 0.179536\n",
      "[5800]\ttraining's binary_logloss: 0.186256\tvalid_1's binary_logloss: 0.179512\n",
      "[5850]\ttraining's binary_logloss: 0.186085\tvalid_1's binary_logloss: 0.179499\n",
      "[5900]\ttraining's binary_logloss: 0.185982\tvalid_1's binary_logloss: 0.17949\n",
      "[5950]\ttraining's binary_logloss: 0.185908\tvalid_1's binary_logloss: 0.179486\n",
      "[6000]\ttraining's binary_logloss: 0.185573\tvalid_1's binary_logloss: 0.179469\n"
     ]
    }
   ],
   "source": [
    "lgb_config['feature_name'] = [col for col in train.columns if col not in [id_name,label_name,'S_2']]\n",
    "test = None\n",
    "Lgb_train_and_predict(train,test,lgb_config,aug=None,output_root='./o_debug/',run_id='LGB_with_manual_feature_and_series_oof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8196ae14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>mean metric</th>\n",
       "      <th>global metric</th>\n",
       "      <th>remark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGB_with_series_feature</td>\n",
       "      <td>0.731081</td>\n",
       "      <td>0.730968</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGB_with_series_feature</td>\n",
       "      <td>0.731057</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGB_with_series_feature</td>\n",
       "      <td>0.731057</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGB_with_manual_feature_and_series_oof</td>\n",
       "      <td>0.812716</td>\n",
       "      <td>0.812520</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGB_with_manual_feature</td>\n",
       "      <td>0.797596</td>\n",
       "      <td>0.797599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGB_with_manual_feature</td>\n",
       "      <td>0.841293</td>\n",
       "      <td>0.841101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGB_with_manual_feature</td>\n",
       "      <td>0.854025</td>\n",
       "      <td>0.853507</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGB_with_manual_feature</td>\n",
       "      <td>0.859919</td>\n",
       "      <td>0.859501</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LGB_with_manual_feature_and_series_oof</td>\n",
       "      <td>0.847463</td>\n",
       "      <td>0.847620</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   run_id  mean metric  global metric  remark\n",
       "0                 LGB_with_series_feature     0.731081       0.730968     NaN\n",
       "1                 LGB_with_series_feature     0.731057       0.730957     NaN\n",
       "2                 LGB_with_series_feature     0.731057       0.730957     NaN\n",
       "3  LGB_with_manual_feature_and_series_oof     0.812716       0.812520     NaN\n",
       "4                 LGB_with_manual_feature     0.797596       0.797599     NaN\n",
       "5                 LGB_with_manual_feature     0.841293       0.841101     NaN\n",
       "6                 LGB_with_manual_feature     0.854025       0.853507     NaN\n",
       "7                 LGB_with_manual_feature     0.859919       0.859501     NaN\n",
       "8  LGB_with_manual_feature_and_series_oof     0.847463       0.847620     NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('o_debug/experiment_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c890bb8",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "052eafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(f'{root}/extra/lgb_main_test_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec63de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[0:462310]\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6c79516",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[462310:]\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ed33008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 462311 entries, 462310 to 924620\n",
      "Columns: 6386 entries, customer_ID to target13\n",
      "dtypes: float32(6328), object(1), uint8(57)\n",
      "memory usage: 10.9+ GB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6de5edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_config['feature_name'] = [col for col in test.columns if col not in [id_name,label_name,'S_2'] and 'target' not in col]\n",
    "train = None\n",
    "Lgb_train_and_predict(train,test,lgb_config,aug=None,output_root='./o_debug/',run_id='LGB_with_manual_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d90d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_config['feature_name'] = [col for col in test.columns if col not in [id_name,label_name,'S_2']]\n",
    "train = None\n",
    "Lgb_train_and_predict(train,test,lgb_config,aug=None,output_root='./o_debug/',run_id='LGB_with_manual_feature_and_series_oof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9efb1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ff46168",
   "metadata": {},
   "source": [
    "## Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add6a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./o_debug/LGB_with_manual_feature/submission.csv.zip') \n",
    "sub_1 = pd.read_csv('./o_debug/LGB_with_manual_feature/submission_1.csv.zip')\n",
    "tmp = pd.concat([sub,sub_1])\n",
    "tmp.to_csv('./o_debug/LGB_with_manual_feature/submission_fnl.csv.zip', compression='zip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "278443b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./o_debug/LGB_with_manual_feature_and_series_oof/submission.csv.zip') \n",
    "sub_1 = pd.read_csv('./o_debug/LGB_with_manual_feature_and_series_oof/submission_1.csv.zip')\n",
    "tmp = pd.concat([sub,sub_1])\n",
    "tmp.to_csv('./o_debug/LGB_with_manual_feature_and_series_oof/submission_fnl.csv.zip', compression='zip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72553978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
